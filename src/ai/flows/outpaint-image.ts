'use server';

/**
 * @fileOverview Expands an image to a 16:9 aspect ratio using Imagen's outpainting feature.
 *
 * - outpaintImage - A function that handles the image outpainting process.
 * - OutpaintImageInput - The input type for the outpaintImage function.
 * - OutpaintImageOutput - The return type for the outpaintImage function.
 */

import {z} from 'zod';
import {v1, helpers} from '@google-cloud/aiplatform';
import Jimp from 'jimp';

// Configure the client
const {PredictionServiceClient} = v1;
const clientOptions = {
  apiEndpoint: 'us-central1-aiplatform.googleapis.com',
};
const predictionServiceClient = new PredictionServiceClient(clientOptions);

const OutpaintImageInputSchema = z.object({
  imageDataUri: z
    .string()
    .describe(
      "The image to outpaint, as a data URI that must include a MIME type and use Base64 encoding. Expected format: 'data:<mimetype>;base64,<encoded_data>'"
    ),
});
export type OutpaintImageInput = z.infer<typeof OutpaintImageInputSchema>;

const OutpaintImageOutputSchema = z.object({
  generatedImageDataUri: z
    .string()
    .describe(
      "The outpainted image, as a data URI that must include a MIME type and use Base64 encoding. Expected format: 'data:<mimetype>;base64,<encoded_data>'"
    ),
});
export type OutpaintImageOutput = z.infer<typeof OutpaintImageOutputSchema>;

export async function outpaintImage(
  input: OutpaintImageInput
): Promise<OutpaintImageOutput> {
  const projectId =
    process.env.GCP_PROJECT || (await predictionServiceClient.getProjectId());
  const location = 'us-central1';

  // This model supports image editing capabilities like outpainting.
  const endpoint = `projects/${projectId}/locations/${location}/publishers/google/models/imagen-3.0-capability-001`;

  const imageMimeType = input.imageDataUri.split(';')[0].split(':')[1];
  const imageBase64 = input.imageDataUri.split(',')[1];
  const imageBuffer = Buffer.from(imageBase64, 'base64');

  // Use jimp to create a mask for outpainting
  const resizeImage = await Jimp.read(imageBuffer);
  const {width, height} = resizeImage.bitmap;
  console.log('resizing image with width: %d, height: %d', width, height);

  let targetWidth = width;
  let targetHeight = height;
  const targetAspectRatio = 16 / 9;
  const originalAspectRatio = width / height;

  if (originalAspectRatio < targetAspectRatio) {
    // Image is taller than 16:9, so expand width
    targetWidth = Math.round(height * targetAspectRatio);
  } else if (originalAspectRatio > targetAspectRatio) {
    // Image is wider than 16:9, so expand height
    targetHeight = Math.round(width / targetAspectRatio);
  } else {
    // Image is already 16:9, no need to outpaint
    return {generatedImageDataUri: input.imageDataUri};
  }
  console.log('resizing image to width: %d, height: %d', targetWidth, targetHeight);

  resizeImage.contain(targetWidth, targetHeight);

  const maskImage = resizeImage.clone();
  maskImage.threshold({max: 1, autoGreyscale: true});
  maskImage.invert();
  console.log('resized image has width: %d, height: %d', maskImage.bitmap.width, maskImage.bitmap.height);

  const resizeImageBuffer = await resizeImage.getBufferAsync(Jimp.MIME_PNG);
  const resizeImageBase64 = resizeImageBuffer.toString('base64');

  const maskBuffer = await maskImage.getBufferAsync(Jimp.MIME_PNG);
  const maskBase64 = maskBuffer.toString('base64');

  const instance = {
    prompt: ``,
    referenceImages: [
      {
        referenceType: "REFERENCE_TYPE_RAW",
        referenceId: 1,
        referenceImage: {
          bytesBase64Encoded: resizeImageBase64,
          mimeType: Jimp.MIME_PNG,
        },
      },
      {
        referenceType: "REFERENCE_TYPE_MASK",
        referenceId: 2,
        referenceImage: {
          bytesBase64Encoded: maskBase64,
          mimeType: Jimp.MIME_PNG,
        },
        maskImageConfig: {
          maskMode: "MASK_MODE_USER_PROVIDED"
        }
      },
    ]
  };

  const instances = [helpers.toValue(instance)];

  const parameters = helpers.toValue({
    sampleCount: 1,
    editMode: "EDIT_MODE_OUTPAINT",
    editConfig: {
      outpaintingConfig: {
        blendingMode: "alpha-blending",
        blendingFactor: 0.01,
      },
    }
  });

  const request = {
    endpoint,
    instances,
    parameters,
  };

  try {
    const [response] = await predictionServiceClient.predict(request);

    if (!response.predictions || response.predictions.length === 0) {
      throw new Error('No image was generated by Vertex AI for outpainting.');
    }

    const prediction = helpers.fromValue(response.predictions[0] as any);

    if (!prediction || !prediction.bytesBase64Encoded) {
      throw new Error('No image data found in Vertex AI response for outpainting.');
    }

    const generatedImageDataUri = `data:image/png;base64,${prediction.bytesBase64Encoded}`;

    return {generatedImageDataUri};
  } catch (error) {
    console.error('Vertex AI Outpainting Prediction Error:', error);
    throw new Error('Failed to outpaint image with Vertex AI.');
  }
}
