'use server';

/**
 * @fileOverview Generates an image of a person from a text description using the @google-cloud/aiplatform library.
 *
 * - generatePersonImage - A function that handles the person image generation.
 * - GeneratePersonImageInput - The input type for the generatePersonImage function.
 * - GeneratePersonImageOutput - The return type for the generatePersonImage function.
 */

import {z} from 'zod';
import {v1} from '@google-cloud/aiplatform';
import {helpers} from '@google-cloud/aiplatform';

// Configure the client
const {PredictionServiceClient} = v1;
const clientOptions = {
  apiEndpoint: 'us-central1-aiplatform.googleapis.com',
};
const predictionServiceClient = new PredictionServiceClient(clientOptions);

const GeneratePersonImageInputSchema = z.object({
  description: z.string().describe('A text description of the person.'),
});
export type GeneratePersonImageInput = z.infer<typeof GeneratePersonImageInputSchema>;

const GeneratePersonImageOutputSchema = z.object({
  imageDataUri: z
    .string()
    .describe(
      "The generated person image, as a data URI that must include a MIME type and use Base64 encoding. Expected format: 'data:<mimetype>;base64,<encoded_data>'"
    ),
});
export type GeneratePersonImageOutput = z.infer<typeof GeneratePersonImageOutputSchema>;

export async function generatePersonImage(
  input: GeneratePersonImageInput
): Promise<GeneratePersonImageOutput> {
  // Use the client to automatically discover the project ID
  const projectId = process.env.GCP_PROJECT || (await predictionServiceClient.getProjectId());
  const location = 'us-central1';

  // Use a text-to-image model like Imagen 4.
  const endpoint = `projects/${projectId}/locations/${location}/publishers/google/models/imagen-4.0-fast-generate-preview-06-06`;

  const instance = {
    prompt: `Generate a photorealistic, full-body image of a person on a plain white background, suitable for use in a virtual try-on application. The person should be the main focus. Person description: ${input.description}`,
  };

  const instances = [helpers.toValue(instance)];

  const parameters = helpers.toValue({
    sampleCount: 1,
  });

  const request = {
    endpoint,
    instances,
    parameters,
  };

  try {
    const [response] = await predictionServiceClient.predict(request);

    if (!response.predictions || response.predictions.length === 0) {
      throw new Error('No image was generated by Vertex AI for person.');
    }

    const prediction = helpers.fromValue(response.predictions[0] as any);

    if (!prediction || !prediction.bytesBase64Encoded) {
      throw new Error('No image data found in Vertex AI response for person.');
    }

    const imageDataUri = `data:image/png;base64,${prediction.bytesBase64Encoded}`;

    return {imageDataUri};
  } catch (error) {
    console.error('Vertex AI Person Prediction Error:', error);
    throw new Error('Failed to generate person image with Vertex AI.');
  }
}
