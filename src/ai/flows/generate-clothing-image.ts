'use server';

/**
 * @fileOverview Generates an image of a clothing item from a text description using the @google-cloud/aiplatform library.
 *
 * - generateClothingImage - A function that handles the clothing image generation.
 * - GenerateClothingImageInput - The input type for the generateClothingImage function.
 * - GenerateClothingImageOutput - The return type for the generateClothingImage function.
 */

import {z} from 'zod';
import {v1, helpers} from '@google-cloud/aiplatform';

// Configure the client
const {PredictionServiceClient} = v1;
const clientOptions = {
  apiEndpoint: 'us-central1-aiplatform.googleapis.com',
};
const predictionServiceClient = new PredictionServiceClient(clientOptions);

const GenerateClothingImageInputSchema = z.object({
  description: z.string().describe('A text description of the clothing item.'),
});
export type GenerateClothingImageInput = z.infer<typeof GenerateClothingImageInputSchema>;

const GenerateClothingImageOutputSchema = z.object({
  imageDataUri: z
    .string()
    .describe(
      "The generated clothing image, as a data URI that must include a MIME type and use Base64 encoding. Expected format: 'data:<mimetype>;base64,<encoded_data>'"
    ),
});
export type GenerateClothingImageOutput = z.infer<typeof GenerateClothingImageOutputSchema>;

export async function generateClothingImage(
  input: GenerateClothingImageInput
): Promise<GenerateClothingImageOutput> {
  // Use the client to automatically discover the project ID
  const projectId = process.env.GOOGLE_CLOUD_PROJECT || await predictionServiceClient.getProjectId();
  const location = 'us-central1';

  // Use a text-to-image model like Imagen 4.
  const endpoint = `projects/${projectId}/locations/${location}/publishers/google/models/imagen-4.0-fast-generate-preview-06-06`;

  const instance = {
    prompt: `Generate a photorealistic image of this clothing item on a plain white background, suitable for a product catalog. The item should be the main focus. ${input.description}`,
  };

  const instances = [helpers.toValue(instance)];

  const parameters = helpers.toValue({
    sampleCount: 1,
  });

  const request = {
    endpoint,
    instances,
    parameters,
  };

  try {
    const [response] = await predictionServiceClient.predict(request);

    if (!response.predictions || response.predictions.length === 0) {
      throw new Error('No image was generated by Vertex AI for clothing.');
    }

    const prediction = helpers.fromValue(response.predictions[0] as any);

    if (!prediction || !prediction.bytesBase64Encoded) {
      throw new Error('No image data found in Vertex AI response for clothing.');
    }

    const imageDataUri = `data:image/png;base64,${prediction.bytesBase64Encoded}`;

    return {imageDataUri};
  } catch (error) {
    console.error('Vertex AI Clothing Prediction Error:', error);
    throw new Error('Failed to generate clothing image with Vertex AI.');
  }
}
